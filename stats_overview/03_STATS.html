
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Chapter 3: Inferential statistics &#8212; No BS Stats Notebooks</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Chapter 4: Linear models" href="04_LINEAR_MODELS.html" />
    <link rel="prev" title="Chapter 2: Probability theory" href="02_PROB.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">No BS Stats Notebooks</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    No Bullshit Stats Notebooks
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="00_Introduction.html">
   Statistics overview
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_DATA.html">
     Chapter 1: DATA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_PROB.html">
     Chapter 2: Probability theory
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Chapter 3: Inferential statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_LINEAR_MODELS.html">
     Chapter 4: Linear models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../notebooks/10_DATA.html">
   Chapter 1 — Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks/11_intro_to_data.html">
     Section 1.1 — Introduction to data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks/12_data_in_practice.html">
     Section 1.2 — Data in practice
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks/13_descriptive_statistics.html">
     Section 1.3 — Descriptive statistics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../notebooks/20_PROB.html">
   Chapter 2 — Probability theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks/21_discrete_random_vars.html">
     Section 2.1 — Discrete random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks/22_multiple_random_vars.html">
     Section 2.2 — Multiple random variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks/23_inventory_discrete_dists.html">
     Section 2.3 — Inventory of discrete distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks/24_calculus_prerequisites.html">
     Section 2.4 — Calculus prerequisites
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks/25_continuous_random_vars.html">
     Section 2.5 — Continuous random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks/26_inventory_continuous_dists.html">
     Section 2.6 — Inventory of continuous distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebooks/27_random_samples.html">
     Section 2.7 — Probability models for random samples
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/30_STATS.html">
   Chapter 3 — Inferential statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/40_LINEAR_MODELS.html">
   Chapter 4 — Linear models
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../tutorials/appendix.html">
   Appendix
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/python_tutorial.html">
     Appendix C — Python tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/pandas_tutorial.html">
     Appendix D — Pandas tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/seaborn_tutorial.html">
     Appendix E — Seaborn tutorial
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/minireference/noBSstatsnotebooks/main?urlpath=tree/./stats_overview/03_STATS.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/minireference/noBSstatsnotebooks"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/minireference/noBSstatsnotebooks/issues/new?title=Issue%20on%20page%20%2Fstats_overview/03_STATS.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/stats_overview/03_STATS.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notebook-setup">
   Notebook setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimators">
   Estimators
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#definitions">
     Definitions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#difference-between-group-means">
     Difference between group means
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#particular-value-of-the-estimator-dmeans">
       Particular value of the estimator
       <code class="docutils literal notranslate">
        <span class="pre">
         dmeans
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sampling-distribution-of-the-estimator-dmeans">
       Sampling distribution of the estimator
       <code class="docutils literal notranslate">
        <span class="pre">
         dmeans
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#plot-the-sampling-distribution-of-dmeans">
       Plot the sampling distribution of
       <code class="docutils literal notranslate">
        <span class="pre">
         dmeans
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#theoretical-model-for-the-sampling-distribution-of-dmeans">
       Theoretical model for the sampling distribution of
       <code class="docutils literal notranslate">
        <span class="pre">
         dmeans
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regroup-and-reality-check">
     Regroup and reality check
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#why-are-we-doing-all-this-modelling">
       Why are we doing all this modelling?
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypothesis-testing">
   Hypothesis testing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview-of-the-hypothesis-testing-procedure">
     Overview of the hypothesis testing procedure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpreting-the-results-of-hypothesis-testing-optional">
     Interpreting the results of hypothesis testing (optional)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-by-load-data-again">
     Start by load data again…
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#approach-1-permutation-test-for-hypothesis-testing">
   Approach 1: Permutation test for hypothesis testing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-a-permutation-test">
     Running a permutation test
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#permutations-test-using-scipy">
     Permutations test using SciPy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#discussion">
     Discussion
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#approach-2-analytical-approximations-for-hypothesis-testing">
   Approach 2: Analytical approximations for hypothesis testing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#student-s-t-test-pooled-variance">
     Student’s t-test (pooled variance)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#black-box-approach">
       Black-box approach
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#student-s-t-test-under-the-hood">
       Student’s t-test under the hood
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#welch-s-t-test-unpooled-variances">
       Welch’s t-test (unpooled variances)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-of-question-1">
     Summary of Question 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimating-the-effect-size">
   Estimating the effect size
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#approach-1-estimate-the-effect-size-using-bootstrap-method">
     Approach 1: estimate the effect size using bootstrap method
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#scipy-bootstrap-method">
       SciPy bootstrap method
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#approach-2-estimates-using-analytical-approximation-method">
     Approach 2: Estimates using analytical approximation method
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-pooled-variance">
       Using pooled variance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-unpooled-variance">
       Using unpooled variance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#summary-of-question-2-results">
       Summary of Question 2 results
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standardized-effect-size-optional">
     Standardized effect size (optional)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion-of-amy-s-statistical-analysis">
   Conclusion of Amy’s statistical analysis
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-statistics-for-convincing-others">
     Using statistics for convincing others
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#comparison-of-resampling-methods-and-analytical-approximations">
   Comparison of resampling methods and analytical approximations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other-statistics-topics-in-the-book">
   Other statistics topics in the book
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Chapter 3: Inferential statistics</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notebook-setup">
   Notebook setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimators">
   Estimators
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#definitions">
     Definitions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#difference-between-group-means">
     Difference between group means
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#particular-value-of-the-estimator-dmeans">
       Particular value of the estimator
       <code class="docutils literal notranslate">
        <span class="pre">
         dmeans
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sampling-distribution-of-the-estimator-dmeans">
       Sampling distribution of the estimator
       <code class="docutils literal notranslate">
        <span class="pre">
         dmeans
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#plot-the-sampling-distribution-of-dmeans">
       Plot the sampling distribution of
       <code class="docutils literal notranslate">
        <span class="pre">
         dmeans
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#theoretical-model-for-the-sampling-distribution-of-dmeans">
       Theoretical model for the sampling distribution of
       <code class="docutils literal notranslate">
        <span class="pre">
         dmeans
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regroup-and-reality-check">
     Regroup and reality check
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#why-are-we-doing-all-this-modelling">
       Why are we doing all this modelling?
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypothesis-testing">
   Hypothesis testing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview-of-the-hypothesis-testing-procedure">
     Overview of the hypothesis testing procedure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpreting-the-results-of-hypothesis-testing-optional">
     Interpreting the results of hypothesis testing (optional)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-by-load-data-again">
     Start by load data again…
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#approach-1-permutation-test-for-hypothesis-testing">
   Approach 1: Permutation test for hypothesis testing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-a-permutation-test">
     Running a permutation test
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#permutations-test-using-scipy">
     Permutations test using SciPy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#discussion">
     Discussion
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#approach-2-analytical-approximations-for-hypothesis-testing">
   Approach 2: Analytical approximations for hypothesis testing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#student-s-t-test-pooled-variance">
     Student’s t-test (pooled variance)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#black-box-approach">
       Black-box approach
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#student-s-t-test-under-the-hood">
       Student’s t-test under the hood
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#welch-s-t-test-unpooled-variances">
       Welch’s t-test (unpooled variances)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-of-question-1">
     Summary of Question 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimating-the-effect-size">
   Estimating the effect size
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#approach-1-estimate-the-effect-size-using-bootstrap-method">
     Approach 1: estimate the effect size using bootstrap method
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#scipy-bootstrap-method">
       SciPy bootstrap method
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#approach-2-estimates-using-analytical-approximation-method">
     Approach 2: Estimates using analytical approximation method
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-pooled-variance">
       Using pooled variance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#using-unpooled-variance">
       Using unpooled variance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#summary-of-question-2-results">
       Summary of Question 2 results
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standardized-effect-size-optional">
     Standardized effect size (optional)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion-of-amy-s-statistical-analysis">
   Conclusion of Amy’s statistical analysis
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-statistics-for-convincing-others">
     Using statistics for convincing others
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#comparison-of-resampling-methods-and-analytical-approximations">
   Comparison of resampling methods and analytical approximations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other-statistics-topics-in-the-book">
   Other statistics topics in the book
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-3-inferential-statistics">
<h1>Chapter 3: Inferential statistics<a class="headerlink" href="#chapter-3-inferential-statistics" title="Permalink to this headline">#</a></h1>
<p><a class="reference external" href="https://docs.google.com/document/d/1fwep23-95U-w1QMPU31nOvUnUXE2X3s_Dbk5JuLlKAY/edit#heading=h.uutryzqeo2av">Link to outline</a></p>
<p>Concept map:
<img alt="concepts_STATS.png" src="stats_overview/attachment:09eb3a54-abf3-4e54-bf16-6a6399de6438.png" /></p>
<section id="notebook-setup">
<h2>Notebook setup<a class="headerlink" href="#notebook-setup" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># loading Python modules</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">scipy.stats.distributions</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="c1"># set random seed for repeatability</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># notebooks figs setup</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">)})</span>
<span class="n">blue</span><span class="p">,</span> <span class="n">orange</span>  <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># silence annoying warnings</span>
<span class="kn">import</span> <span class="nn">warnings</span><span class="p">;</span> <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Main idea = learn about a population based on a sample</p></li>
<li><p>Recall Amy’s two research questions about the employee lifetime value (ELV) data:</p>
<ul>
<li><p>Question 1 = Is there a difference between ELV of the two groups? → <strong>hypothesis testing</strong></p></li>
<li><p>Question 2 = How much difference in ELV does stats training provide? → <strong>estimation</strong></p></li>
</ul>
</li>
<li><p>Inferential statistics provides us with tools to answer both of these questions</p></li>
</ul>
</section>
<section id="estimators">
<h2>Estimators<a class="headerlink" href="#estimators" title="Permalink to this headline">#</a></h2>
<p>We’ll begin our study of inferential statistics by introducing <strong>estimators</strong>,
which are used for both <strong>hypothesis testing</strong> and <strong>estimation</strong>.</p>
<p><img alt="high level stats for overview.png" src="stats_overview/attachment:8837c882-ebf7-4203-b625-c8f01f84a55b.png" /></p>
<p><span class="math notranslate nohighlight">\(\def\stderr#1{\mathbf{se}_{#1}}\)</span>
<span class="math notranslate nohighlight">\(\def\stderrhat#1{\hat{\mathbf{se}}_{#1}}\)</span></p>
<section id="definitions">
<h3>Definitions<a class="headerlink" href="#definitions" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>We use the term “estimator” to describe a function <span class="math notranslate nohighlight">\(f\)</span> that takes samples as inputs,
which is written mathematically as:
$<span class="math notranslate nohighlight">\(
 f \ \colon \underbrace{\mathcal{X}\times \mathcal{X}\times \cdots \times \mathcal{X}}_{n \textrm{ copies}}
 \quad \to \quad \mathbb{R},
\)</span><span class="math notranslate nohighlight">\(
where \)</span>n<span class="math notranslate nohighlight">\( is the samples size and \)</span>\mathcal{X}<span class="math notranslate nohighlight">\( denotes the possible values of the random variable \)</span>X$.</p></li>
<li><p>We give different names to estimators, depending on the use case:</p>
<ul>
<li><p><strong>statistic</strong> = a function computed from samples (descriptive statistics)</p></li>
<li><p><strong>parameter estimators</strong> = statistics that estimates population parameters</p></li>
<li><p><strong>test statistic</strong> = an estimator used as part of hypothesis testing procedure</p></li>
</ul>
</li>
<li><p>The <strong>value</strong> of the estimator <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span> is computer from a particular sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p></li>
<li><p>The <strong>sampling distribution</strong> of an estimator is when <span class="math notranslate nohighlight">\(f\)</span> is the distribution of <span class="math notranslate nohighlight">\(f(\mathbf{X})\)</span>,
where <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is a random sample.</p></li>
<li><p>Example of estimators we discussed in descriptive statistics:</p>
<ul>
<li><p>Sample mean</p>
<ul>
<li><p>estimator: <span class="math notranslate nohighlight">\(\overline{x} = g(\mathbf{x}) = \frac{1}{n}\sum_{i=1}^n x_i\)</span></p></li>
<li><p>gives an estimate for the population mean <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
<li><p>sampling distribution: <span class="math notranslate nohighlight">\(\overline{X} = g(\mathbf{X}) = \frac{1}{n}\sum_{i=1}^n X_i\)</span></p></li>
</ul>
</li>
<li><p>Sample variance</p>
<ul>
<li><p>estimator: <span class="math notranslate nohighlight">\(s^2 = h(\mathbf{x}) = \frac{1}{n-1}\sum_{i=1}^n (x_i-\overline{x})^2\)</span></p></li>
<li><p>gives an estimate for the population variance <span class="math notranslate nohighlight">\(\sigma^2\)</span></p></li>
<li><p>sampling distribution: <span class="math notranslate nohighlight">\(S^2 = h(\mathbf{X}) = \frac{1}{n-1}\sum_{i=1}^n (X_i-\overline{X})^2\)</span></p></li>
</ul>
</li>
</ul>
</li>
<li><p>In this notebook we focus on one estimator: <strong>difference between group means</strong></p>
<ul>
<li><p>estimator: <span class="math notranslate nohighlight">\(d = \texttt{mean}(\mathbf{x}_A) - \texttt{mean}(\mathbf{x}_{B}) = \overline{x}_{A} - \overline{x}_{B}\)</span></p></li>
<li><p>gives an estimate for the difference between population means: <span class="math notranslate nohighlight">\(\Delta =  \mu_A - \mu_{B}\)</span></p></li>
<li><p>sampling distribution: <span class="math notranslate nohighlight">\(D = \overline{X}_A - \overline{X}_{B}\)</span>, which is a random variable</p></li>
</ul>
</li>
</ul>
</section>
<section id="difference-between-group-means">
<h3>Difference between group means<a class="headerlink" href="#difference-between-group-means" title="Permalink to this headline">#</a></h3>
<p>Consider two random variables <span class="math notranslate nohighlight">\(X_A\)</span> and <span class="math notranslate nohighlight">\(X_B\)</span>:
$<span class="math notranslate nohighlight">\( \large
X_A \sim \mathcal{N}\!\left(\mu_A, \sigma^2_A \right)
\qquad
\textrm{and}
\qquad
X_B \sim \mathcal{N}\!\left(\mu_B, \sigma^2_B \right)
\)</span>$
that describe the probability distribution for groups A and B, respectively.</p>
<ul class="simple">
<li><p>A sample of size <span class="math notranslate nohighlight">\(n_A\)</span> from <span class="math notranslate nohighlight">\(X_A\)</span> is denoted <span class="math notranslate nohighlight">\(\mathbf{x}_A = x_1x_2\cdots x_{n_A}\)</span>=<code class="docutils literal notranslate"><span class="pre">xA</span></code>, and let <span class="math notranslate nohighlight">\(\mathbf{x}_B = x_1x_2\cdots x_{n_B}\)</span>=<code class="docutils literal notranslate"><span class="pre">xB</span></code> be a random sample of size <span class="math notranslate nohighlight">\(n_B\)</span> from <span class="math notranslate nohighlight">\(X_B\)</span>.</p></li>
<li><p>We compute the mean in each group: <span class="math notranslate nohighlight">\(\overline{x}_{A} = \texttt{mean}(\mathbf{x}_A)\)</span>
and <span class="math notranslate nohighlight">\(\overline{x}_{B} = \texttt{mean}(\mathbf{x}_B)\)</span></p></li>
<li><p>The value of the estimator is <span class="math notranslate nohighlight">\(d = \overline{x}_{A} - \overline{x}_{B}\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">dmeans</span><span class="p">(</span><span class="n">xA</span><span class="p">,</span> <span class="n">xB</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimator for the difference between group means.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xA</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xB</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span>
</pre></div>
</div>
</div>
</div>
<p>Note the difference between group means is precisely the estimator Amy need for her analysis (<strong>Group S</strong> and <strong>Group NS</strong>). We intentionally use the labels <strong>A</strong> and <strong>B</strong> to illustrate the general case.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># example parameters for each group</span>
<span class="n">muA</span><span class="p">,</span> <span class="n">sigmaA</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">muB</span><span class="p">,</span> <span class="n">sigmaB</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">20</span>

<span class="c1"># size of samples for each group</span>
<span class="n">nA</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">nB</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
</div>
</div>
<section id="particular-value-of-the-estimator-dmeans">
<h4>Particular value of the estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code><a class="headerlink" href="#particular-value-of-the-estimator-dmeans" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xA</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">muA</span><span class="p">,</span> <span class="n">sigmaA</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nA</span><span class="p">)</span>  <span class="c1"># random sample from Group A</span>
<span class="n">xB</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">muB</span><span class="p">,</span> <span class="n">sigmaB</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nB</span><span class="p">)</span>  <span class="c1"># random sample from Group B</span>

<span class="n">d</span> <span class="o">=</span> <span class="n">dmeans</span><span class="p">(</span><span class="n">xA</span><span class="p">,</span> <span class="n">xB</span><span class="p">)</span>
<span class="n">d</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>96.37484873437
</pre></div>
</div>
</div>
</div>
<p>The value of <span class="math notranslate nohighlight">\(d\)</span> computed from the samples is an estimate for the difference between means of two groups: <span class="math notranslate nohighlight">\(\Delta =  \mu_A - \mu_{B}\)</span> (which we know is <span class="math notranslate nohighlight">\(100\)</span> in this example).</p>
</section>
<section id="sampling-distribution-of-the-estimator-dmeans">
<h4>Sampling distribution of the estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code><a class="headerlink" href="#sampling-distribution-of-the-estimator-dmeans" title="Permalink to this headline">#</a></h4>
<p>How well does the estimate <span class="math notranslate nohighlight">\(d\)</span> approximate the true value <span class="math notranslate nohighlight">\(\Delta\)</span>?
<strong>What is the accuracy and variability of the estimates we can expect?</strong></p>
<p>To answer these questions, consider the random samples
<span class="math notranslate nohighlight">\(\mathbf{X}_A = X_1X_2\cdots X_{n_A}\)</span>
and <span class="math notranslate nohighlight">\(\mathbf{X}_B = X_1X_2\cdots X_{n_B}\)</span>,
then compute the <strong>sampling distribution</strong>: <span class="math notranslate nohighlight">\(D = \overline{X}_A - \overline{X}_{B}\)</span>.</p>
<p>By definition, the sampling distribution of the estimator is obtained by repeatedly generating samples <code class="docutils literal notranslate"><span class="pre">xA</span></code> and <code class="docutils literal notranslate"><span class="pre">xB</span></code> from the two distributions and computing <code class="docutils literal notranslate"><span class="pre">dmeans</span></code> on the random samples. For example, we can obtain the sampling distribution by generating <span class="math notranslate nohighlight">\(N=1000\)</span> samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_sampling_dist</span><span class="p">(</span><span class="n">statfunc</span><span class="p">,</span> <span class="n">meanA</span><span class="p">,</span> <span class="n">stdA</span><span class="p">,</span> <span class="n">nA</span><span class="p">,</span> <span class="n">meanB</span><span class="p">,</span> <span class="n">stdB</span><span class="p">,</span> <span class="n">nB</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Obtain the sampling distribution of the statistic `statfunc`</span>
<span class="sd">    from `N` random samples drawn from groups A and B with parmeters:</span>
<span class="sd">      - Group A: `nA` values taken from `norm(meanA, stdA)`</span>
<span class="sd">      - Group B: `nB` values taken from `norm(meanB, stdB)`</span>
<span class="sd">    Returns a list of samples from the sampling distribution of `statfunc`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sampling_dist</span> <span class="o">=</span> <span class="p">[]</span> 
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="n">xA</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">meanA</span><span class="p">,</span> <span class="n">stdA</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nA</span><span class="p">)</span>  <span class="c1"># random sample from Group A</span>
        <span class="n">xB</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">meanB</span><span class="p">,</span> <span class="n">stdB</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nB</span><span class="p">)</span>  <span class="c1"># random sample from Group B</span>
        <span class="n">stat</span> <span class="o">=</span> <span class="n">statfunc</span><span class="p">(</span><span class="n">xA</span><span class="p">,</span> <span class="n">xB</span><span class="p">)</span>         <span class="c1"># evaluate `statfunc`</span>
        <span class="n">sampling_dist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stat</span><span class="p">)</span>      <span class="c1"># record the value of statfunc</span>
    <span class="k">return</span> <span class="n">sampling_dist</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate the sampling distirbution for dmeans</span>
<span class="n">dmeans_sdist</span> <span class="o">=</span> <span class="n">get_sampling_dist</span><span class="p">(</span><span class="n">statfunc</span><span class="o">=</span><span class="n">dmeans</span><span class="p">,</span>
                                 <span class="n">meanA</span><span class="o">=</span><span class="n">muA</span><span class="p">,</span> <span class="n">stdA</span><span class="o">=</span><span class="n">sigmaA</span><span class="p">,</span> <span class="n">nA</span><span class="o">=</span><span class="n">nA</span><span class="p">,</span>
                                 <span class="n">meanB</span><span class="o">=</span><span class="n">muB</span><span class="p">,</span> <span class="n">stdB</span><span class="o">=</span><span class="n">sigmaB</span><span class="p">,</span> <span class="n">nB</span><span class="o">=</span><span class="n">nB</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dmeans_sdist</span><span class="p">),</span> <span class="s2">&quot;values from `dmeans(XA, XB)`&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Generated 1000 values from `dmeans(XA, XB)`
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># first 3 values</span>
<span class="n">dmeans_sdist</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[110.81313499568878, 113.02015528478827, 108.81540875963461]
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-the-sampling-distribution-of-dmeans">
<h4>Plot the sampling distribution of <code class="docutils literal notranslate"><span class="pre">dmeans</span></code><a class="headerlink" href="#plot-the-sampling-distribution-of-dmeans" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig3</span><span class="p">,</span> <span class="n">ax3</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">title3</span> <span class="o">=</span> <span class="s2">&quot;Samping distribution of D = mean($\mathbf</span><span class="si">{X}</span><span class="s2">_A$) - mean($\mathbf</span><span class="si">{X}</span><span class="s2">_B$) &quot;</span> <span class="o">+</span> \
         <span class="s2">&quot;for samples of size $n_A$ = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">nA</span><span class="p">)</span> <span class="o">+</span> \
         <span class="s2">&quot; from $\mathcal</span><span class="si">{N}</span><span class="s2">$(&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">muA</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;,&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sigmaA</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span> <span class="o">+</span> \
         <span class="s2">&quot; and $n_B$ = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">nB</span><span class="p">)</span> <span class="o">+</span> \
         <span class="s2">&quot; from $\mathcal</span><span class="si">{N}</span><span class="s2">$(&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">muB</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;,&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sigmaB</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">dmeans_sdist</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">norm_hist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax3</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03_STATS_22_0.png" src="../_images/03_STATS_22_0.png" />
</div>
</div>
</section>
<section id="theoretical-model-for-the-sampling-distribution-of-dmeans">
<h4>Theoretical model for the sampling distribution of <code class="docutils literal notranslate"><span class="pre">dmeans</span></code><a class="headerlink" href="#theoretical-model-for-the-sampling-distribution-of-dmeans" title="Permalink to this headline">#</a></h4>
<p>Let’s use probability theory to build a theoretical model for the sampling distribution of the difference-between-means estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code>.</p>
<ul class="simple">
<li><p>The central limit theorem</p></li>
</ul>
<p>the rules of  to obtain a model for the random variable <span class="math notranslate nohighlight">\(D = \overline{X}_A - \overline{X}_{B}\)</span>,
which describes the sampling distribution of  <code class="docutils literal notranslate"><span class="pre">dmeans</span></code>.</p>
<ul class="simple">
<li><p>The central limit theorem tells us the sample mean within the two group are
$<span class="math notranslate nohighlight">\( \large
\overline{X}_A \sim \mathcal{N}\!\left(\mu_A, \tfrac{\sigma^2_A}{n_A} \right)
\qquad \textrm{and} \qquad
\overline{X}_B \sim \mathcal{N}\!\left(\mu_B, \tfrac{\sigma^2_B}{n_B} \right)
\)</span>$</p></li>
<li><p>The rules of probability theory tells us that the <a class="reference external" href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables#Independent_random_variables">difference of two normal random variables</a> requires subtracting their means and adding their variance, so we get:
$<span class="math notranslate nohighlight">\( \large
D \sim \mathcal{N}\!\left(\mu_A - \mu_B, \  \tfrac{\sigma^2_A}{n_A} + \tfrac{\sigma^2_B}{n_B} \right)
\)</span>$</p></li>
</ul>
<p>In other words, the sampling distribution for the difference of means estimator has mean and standard deviation given by:
$<span class="math notranslate nohighlight">\( \large
   \mu_D = \mu_A - \mu_B
   \qquad \textrm{and} \qquad
   \sigma_D = \sqrt{ \tfrac{\sigma^2_A}{n_A} + \tfrac{\sigma^2_B}{n_B}  }
\)</span>$</p>
<p>Let’s plot the theoretical prediction on top of the simulated data to see if they are a good fit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Dmean</span> <span class="o">=</span> <span class="n">muA</span> <span class="o">-</span> <span class="n">muB</span>
<span class="n">Dstd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigmaA</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nA</span> <span class="o">+</span> <span class="n">sigmaB</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nB</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Probability theory predicts the sampling distribution had&quot;</span>
      <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">Dmean</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
      <span class="s2">&quot;and standard deviation&quot;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">Dstd</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">dmeans_sdist</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">dmeans_sdist</span><span class="p">),</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">Dmean</span><span class="p">,</span> <span class="n">Dstd</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Theory prediction&#39;</span>
<span class="n">ax3</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">blue</span><span class="p">)</span>
<span class="n">fig3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Probability theory predicts the sampling distribution hadmean 100 and standard deviation 10.954
</pre></div>
</div>
<img alt="../_images/03_STATS_25_1.png" src="../_images/03_STATS_25_1.png" />
</div>
</div>
</section>
</section>
<section id="regroup-and-reality-check">
<h3>Regroup and reality check<a class="headerlink" href="#regroup-and-reality-check" title="Permalink to this headline">#</a></h3>
<p>How are you doing, dear readers?
I know this was a lot of math and a lot of code, but the good news is we’re done now!
The key things to remember is that we have two ways to compute sampling distribution for any estimator:</p>
<ul class="simple">
<li><p>Repeatedly generate random samples from model and compute the estimator values (histogram)</p></li>
<li><p>Use probability theory to obtain a analytical formula</p></li>
</ul>
<section id="why-are-we-doing-all-this-modelling">
<h4>Why are we doing all this modelling?<a class="headerlink" href="#why-are-we-doing-all-this-modelling" title="Permalink to this headline">#</a></h4>
<p>The estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code> we defined above measures the quantity we’re interested in:
the difference between the means of two groups (<strong>Group S</strong> and <strong>Group NS</strong> in Amy’s statistical analysis of ELV data).</p>
<p>Using the functions we developed above, we now have the ability to simulate the data from any two groups by simply choosing the appropriate parameters. In particular if we choose <code class="docutils literal notranslate"><span class="pre">stdS=266</span></code>, <code class="docutils literal notranslate"><span class="pre">nS=30</span></code>; and <code class="docutils literal notranslate"><span class="pre">stdNS=233</span></code>, <code class="docutils literal notranslate"><span class="pre">nNS=31</span></code>,
we can generate random data that has similar variability to Amy ELV measurements.</p>
<p>Okay, dear reader, we’re about to jump into the deep end of the statistics pool: <strong>hypothesis testing</strong>,
which is one of the two major ideas in the STATS 101 curriculum.
Heads up this will get complicated, but we have to go into it because it is an essential procedure
that is used widely in science, engineering, business, and other types of research.
You need to trust me this one: it’s worth knowing this stuff, even if it is boring.
Don’t worry about it though, since you have all the prerequisites needed to get through this!</p>
<hr class="docutils" />
<p>Recall Amy’s research Question 1:</p>
<p>Is there a difference between ELV of the employees in <strong>Group S</strong> and the employees in <strong>Group NS</strong>?</p>
</section>
</section>
</section>
<section id="hypothesis-testing">
<h2>Hypothesis testing<a class="headerlink" href="#hypothesis-testing" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>An approach to formulating research questions as <strong>yes-no decisions</strong> and a <strong>procedure for making these decisions</strong></p></li>
<li><p>Hypothesis testing is a standardized procedure for doing statistical analysis<br />
(also, using stats jargon makes everything look more convincing ;)</p></li>
<li><p>We formulate research question as two <strong>competing hypotheses</strong>:</p>
<ul>
<li><p><strong>Null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span></strong> = no effect<br />
in our example: “no difference between means,” which is written as <span class="math notranslate nohighlight">\(\color{red}{\mu_S = \mu_{NS} = \mu_0}\)</span>.
In other words, the probability models for the two groups are:
$<span class="math notranslate nohighlight">\( \large
   H_0: \qquad X_S = \mathcal{N}(\color{red}{\mu_0}, \sigma_S)
   \quad \textrm{and} \quad
   X_{NS} = \mathcal{N}(\color{red}{\mu_0}, \sigma_{NS}) \quad
\)</span>$</p></li>
<li><p><strong>Alternative hypothesis <span class="math notranslate nohighlight">\(H_A\)</span></strong> = an effect exists<br />
in our example: “means for Group S different from mean for Group NS”,  <span class="math notranslate nohighlight">\(\color{blue}{\mu_S} \neq \color{orange}{\mu_{NS}}\)</span>.
The probability models for the two groups are:
$<span class="math notranslate nohighlight">\( 
   H_A: \qquad X_S = \mathcal{N}(\color{blue}{\mu_S}, \sigma_S)
   \quad \textrm{and} \quad
   X_{NS} = \mathcal{N}(\color{orange}{\mu_{NS}}, \sigma_{NS})
\)</span>$</p></li>
</ul>
</li>
<li><p>The purpose of hypothesis testing is to perform a basic sanity-check to show the difference between the group means
we observed (<span class="math notranslate nohighlight">\(d = \overline{x}_{S} - \overline{x}_{NS} = 130\)</span>) is <strong>unlikely to have occurred by chance</strong></p></li>
<li><p>NEW CONCEPT: <span class="math notranslate nohighlight">\(p\)</span>-value is the probability of observing <span class="math notranslate nohighlight">\(d\)</span> or more extreme under the null hypothesis.</p></li>
</ul>
<section id="overview-of-the-hypothesis-testing-procedure">
<h3>Overview of the hypothesis testing procedure<a class="headerlink" href="#overview-of-the-hypothesis-testing-procedure" title="Permalink to this headline">#</a></h3>
<p>Here is the high-level overview of the hypothesis testing procedure:</p>
<ul class="simple">
<li><p><strong>inputs</strong>: sample statistics computed from the observed data
(in our case the signal <span class="math notranslate nohighlight">\(\overline{x}_S\)</span>, <span class="math notranslate nohighlight">\(\overline{x}_{NS}\)</span>,
and our estimates of the noise <span class="math notranslate nohighlight">\(s^2_S\)</span>, and <span class="math notranslate nohighlight">\(s^2_{NS}\)</span>)</p></li>
<li><p><strong>outputs</strong>: a decision that is one of: “reject the null hypothesis” or “fail to reject the null hypothesis”</p></li>
</ul>
<p><img alt="hypothesis testing for overview.png" src="stats_overview/attachment:f1abf698-e8fb-4844-aeb8-58df5352b68f.png" /></p>
<p>We’ll now look at two different approaches for computing the sampling distribution of
the difference between group means statistic, <span class="math notranslate nohighlight">\(D = \overline{X}_S - \overline{X}_{NS}\)</span>:
permutation tests and analytical approximations.</p>
</section>
<section id="interpreting-the-results-of-hypothesis-testing-optional">
<h3>Interpreting the results of hypothesis testing (optional)<a class="headerlink" href="#interpreting-the-results-of-hypothesis-testing-optional" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>The implication of rejecting the null hypothesis (no difference) is that there must is a difference between the group means.
In other words, the ELV data for employees who took the statistics training (<strong>Group S</strong>) is different form
the average ELV for employees who didn’t take the statistics training (<strong>Group NS</strong>),
which is what Amy is trying to show.</p>
<ul>
<li><p>Note that rejecting null hypothesis (H0) is not the same as “proving” the alternative hypothesis (HA),
we have just shown that the data is unlikely under the null hypothesis and we must be <em>some</em> difference between the groups,
so is worth looking for <em>some</em> alternative hypothesis.</p></li>
<li><p>The alternative hypothesis we picked above, <span class="math notranslate nohighlight">\(\mu_S \neq \mu_{NS}\)</span>, is just a placeholder,
that includes desirable effect: <span class="math notranslate nohighlight">\(\mu_S &gt; \mu_{NS}\)</span> (stats training improves ELV),
but also includes the opposite effect: <span class="math notranslate nohighlight">\(\mu_S &lt; \mu_{NS}\)</span> (stats training decreases ELV).</p></li>
<li><p>Using statistics jargon, when we reject the hypothesis H0 we say we’ve observed a “statistically significant” result,
which sounds a lot more impressive statement than it actually is.
Recall hypothesis test is just used to rule out “occurred by chance,” which is a very basic sanity check.</p></li>
</ul>
</li>
<li><p>The implication of failing to reject the null hypothesis is that the observed difference
between means is “not significant,” meaning it could have occurred by chance,
so there is no need to search for an alternative hypothesis.</p>
<ul>
<li><p>Note that “failing to reject” is not the same as “proving” the null hypothesis</p></li>
<li><p>Note also “failing to reject H0” doesn’t mean we reject HA.
In fact, the alternative hypothesis didn’t play any role in the calculations whatsoever.</p></li>
</ul>
</li>
</ul>
<p>I know all this sounds super complicated and roundabout (an it is!),
but you will get a hang of it in no time with some practice.
Trust me, you need to know this shit.</p>
</section>
<section id="start-by-load-data-again">
<h3>Start by load data again…<a class="headerlink" href="#start-by-load-data-again" title="Permalink to this headline">#</a></h3>
<p>First things first, let’s reload the data which we prepared back in the DATA where we left off back in the <a class="reference internal" href="01_DATA.html"><span class="doc std std-doc">01_DATA.ipynb</span></a> notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/employee_lifetime_values.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>group</th>
      <th>ELV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NS</td>
      <td>923.87</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NS</td>
      <td>751.38</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NS</td>
      <td>432.83</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NS</td>
      <td>1417.36</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NS</td>
      <td>973.24</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>56</th>
      <td>S</td>
      <td>931.61</td>
    </tr>
    <tr>
      <th>57</th>
      <td>S</td>
      <td>1329.68</td>
    </tr>
    <tr>
      <th>58</th>
      <td>S</td>
      <td>1293.03</td>
    </tr>
    <tr>
      <th>59</th>
      <td>S</td>
      <td>1240.44</td>
    </tr>
    <tr>
      <th>60</th>
      <td>S</td>
      <td>1105.59</td>
    </tr>
  </tbody>
</table>
<p>61 rows × 2 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># remember the descriptive statistics</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;group&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="8" halign="left">ELV</th>
    </tr>
    <tr>
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>group</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>NS</th>
      <td>31.0</td>
      <td>1018.41129</td>
      <td>265.815869</td>
      <td>432.83</td>
      <td>858.7750</td>
      <td>990.130</td>
      <td>1183.2750</td>
      <td>1620.93</td>
    </tr>
    <tr>
      <th>S</th>
      <td>30.0</td>
      <td>1148.43500</td>
      <td>233.037704</td>
      <td>623.06</td>
      <td>1022.1375</td>
      <td>1119.305</td>
      <td>1279.8825</td>
      <td>1716.61</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">dmeans</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the difference between groups means.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xS</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;S&quot;</span><span class="p">][</span><span class="s2">&quot;ELV&quot;</span><span class="p">]</span>
    <span class="n">xNS</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;NS&quot;</span><span class="p">][</span><span class="s2">&quot;ELV&quot;</span><span class="p">]</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xS</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span>

<span class="c1"># the observed value in Amy&#39;s data</span>
<span class="n">dmeans</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>130.02370967741933
</pre></div>
</div>
</div>
</div>
<p>Our goal is to determine how likely or unlikely this observed value is under the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<p>In the next two sections, we’ll look at two different approaches for obtaining the sampling distribution of <span class="math notranslate nohighlight">\(D\)</span> under <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
</section>
</section>
<section id="approach-1-permutation-test-for-hypothesis-testing">
<h2>Approach 1: Permutation test for hypothesis testing<a class="headerlink" href="#approach-1-permutation-test-for-hypothesis-testing" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>The permutation test allow us to reject <span class="math notranslate nohighlight">\(H_0\)</span> using existing sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> that we have,
treating the sample as if it were a population.</p></li>
<li><p>Relevant probability distributions:</p>
<ul>
<li><p>Sampling distribution = obtained from repeated samples from a hypothetical population under <span class="math notranslate nohighlight">\(H_0\)</span>.</p></li>
<li><p>Approximate sampling distribution: obtained by <strong>resampling data from the single sample we have</strong>.</p></li>
</ul>
</li>
<li><p>Recall Goal 1: make sure data cannot be explained by <span class="math notranslate nohighlight">\(H_0\)</span> (observed difference due to natural variability)</p>
<ul>
<li><p>We want to obtain an approximation of the sampling distribution under <span class="math notranslate nohighlight">\(H_0\)</span></p></li>
<li><p>The <span class="math notranslate nohighlight">\(H_0\)</span> probability model describes a hypothetical scenario with <strong>no difference between groups</strong>,
which means data from <strong>Group S</strong> and <strong>Group NS</strong> comes the same distribution.</p></li>
<li><p>To generate a new random sample <span class="math notranslate nohighlight">\(\mathbf{x}^p\)</span> from <span class="math notranslate nohighlight">\(H_0\)</span> model we can reuse the sample we have obtained <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, but randomly mix-up the group labels. Since under the <span class="math notranslate nohighlight">\(H_0\)</span> model, the <strong>S</strong> and <strong>NS</strong> populations are identical, mixing up the labels should have no effect.</p></li>
<li><p>The math term for “mixing up” is <strong>permutation</strong>, meaning
each value is input is randomly reassigned to a new random place in the output.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">resample_under_H0</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">groupcol</span><span class="o">=</span><span class="s2">&quot;group&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a copy of the dataframe `sample` with the labels in the column `groupcol`</span>
<span class="sd">    modified based on a random permutation of the values in the original sample.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">resample</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">groupcol</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">newlabels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">resample</span><span class="p">[</span><span class="n">groupcol</span><span class="p">]</span> <span class="o">=</span> <span class="n">newlabels</span>
    <span class="k">return</span> <span class="n">resample</span>

<span class="n">resample_under_H0</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>group</th>
      <th>ELV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S</td>
      <td>923.87</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NS</td>
      <td>751.38</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S</td>
      <td>432.83</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NS</td>
      <td>1417.36</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NS</td>
      <td>973.24</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>56</th>
      <td>S</td>
      <td>931.61</td>
    </tr>
    <tr>
      <th>57</th>
      <td>NS</td>
      <td>1329.68</td>
    </tr>
    <tr>
      <th>58</th>
      <td>NS</td>
      <td>1293.03</td>
    </tr>
    <tr>
      <th>59</th>
      <td>S</td>
      <td>1240.44</td>
    </tr>
    <tr>
      <th>60</th>
      <td>NS</td>
      <td>1105.59</td>
    </tr>
  </tbody>
</table>
<p>61 rows × 2 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># resample</span>
<span class="n">resample</span> <span class="o">=</span> <span class="n">resample_under_H0</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># compute the difference in means for the new labels</span>
<span class="n">dmeans</span><span class="p">(</span><span class="n">resample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-29.60082795698918
</pre></div>
</div>
</div>
</div>
<p>The steps in the above code cell give us a simple way to generate samples from the null hypothesis and compute the value of <code class="docutils literal notranslate"><span class="pre">dmeans</span></code> statistic for these samples. We used the assumption of “no difference” under the null hypothesis, and translated this to the “forget the labels” interpretation.</p>
<section id="running-a-permutation-test">
<h3>Running a permutation test<a class="headerlink" href="#running-a-permutation-test" title="Permalink to this headline">#</a></h3>
<p>We can repeat the resampling procedure <code class="docutils literal notranslate"><span class="pre">10000</span></code> times to get the sampling distribution of <span class="math notranslate nohighlight">\(D\)</span> under <span class="math notranslate nohighlight">\(H_0\)</span>,
as illustrated in the code procedure below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">permutation_test</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">statfunc</span><span class="p">,</span> <span class="n">groupcol</span><span class="o">=</span><span class="s2">&quot;group&quot;</span><span class="p">,</span> <span class="n">permutations</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the p-value of the observed `statfunc(sample)` under the null hypothesis</span>
<span class="sd">    where the labels in the `groupcol` are randomized.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1. compute the observed value of the statistic for the sample</span>
    <span class="n">obsstat</span> <span class="o">=</span> <span class="n">statfunc</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

    <span class="c1"># 2. generate the sampling distr. using random permutations of the group labels</span>
    <span class="n">resampled_stats</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">permutations</span><span class="p">):</span>
        <span class="n">resample</span> <span class="o">=</span> <span class="n">resample_under_H0</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">groupcol</span><span class="o">=</span><span class="n">groupcol</span><span class="p">)</span>
        <span class="n">restat</span> <span class="o">=</span> <span class="n">statfunc</span><span class="p">(</span><span class="n">resample</span><span class="p">)</span>
        <span class="n">resampled_stats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">restat</span><span class="p">)</span>

    <span class="c1"># 3. compute p-value: how many `restat`s are equal-or-more-extreme than `obsstat`</span>
    <span class="n">tailstats</span> <span class="o">=</span> <span class="p">[</span><span class="n">restat</span> <span class="k">for</span> <span class="n">restat</span> <span class="ow">in</span> <span class="n">resampled_stats</span> \
                 <span class="k">if</span> <span class="n">restat</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">obsstat</span><span class="p">)</span> <span class="ow">or</span> <span class="n">restat</span> <span class="o">&gt;=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">obsstat</span><span class="p">)]</span>
    <span class="n">pvalue</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tailstats</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">resampled_stats</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">resampled_stats</span><span class="p">,</span> <span class="n">pvalue</span>


<span class="n">sampling_dist</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">permutation_test</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">statfunc</span><span class="o">=</span><span class="n">dmeans</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the sampling distribution in blue</span>
<span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">sampling_dist</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="c1"># plot red line for the observed statistic</span>
<span class="n">obsstat</span> <span class="o">=</span> <span class="n">dmeans</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">obsstat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="c1"># plot the values that are equal or more extreme in red</span>
<span class="n">tailstats</span> <span class="o">=</span> <span class="p">[</span><span class="n">rs</span> <span class="k">for</span> <span class="n">rs</span> <span class="ow">in</span> <span class="n">sampling_dist</span> <span class="k">if</span> <span class="n">rs</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">obsstat</span> <span class="ow">or</span> <span class="n">rs</span> <span class="o">&gt;=</span> <span class="n">obsstat</span><span class="p">]</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">tailstats</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03_STATS_50_0.png" src="../_images/03_STATS_50_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Once we have the sampling distribution of <code class="docutils literal notranslate"><span class="pre">D</span></code> under <span class="math notranslate nohighlight">\(H_0\)</span>,
we can see where the observed value <span class="math notranslate nohighlight">\(d=130\)</span>
falls within this distribution.</p></li>
<li><p>p-value: the probability of observing value <span class="math notranslate nohighlight">\(d\)</span> or more extreme under the null hypothesis</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.046
</pre></div>
</div>
</div>
</div>
<p>We can now make the decision based on the <span class="math notranslate nohighlight">\(p\)</span>-value and a pre-determined threshold:</p>
<ul class="simple">
<li><p>If the observed value <span class="math notranslate nohighlight">\(d\)</span> is unlikely under <span class="math notranslate nohighlight">\(H_0\)</span> (<span class="math notranslate nohighlight">\(p\)</span>-value less than 5% chance of occurring),
then our decision will be to “reject the null hypothesis.”</p></li>
<li><p>Otherwise, if the observed value <span class="math notranslate nohighlight">\(d\)</span> is not that unusual (<span class="math notranslate nohighlight">\(p\)</span>-value greater than 5%),
we conclude that we have “failed to reject the null hypothesis.”</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DECISION: Reject H0&quot;</span><span class="p">,</span> <span class="s2">&quot;( p-value =&quot;</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="s2">&quot;)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;          There is a statistically significant difference between xS and xNS means&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DECISION: Fail to reject H0&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;          The difference between groups means could have occurred by chance&quot;</span><span class="p">)</span>    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DECISION: Reject H0 ( p-value = 0.046 )
          There is a statistically significant difference between xS and xNS means
</pre></div>
</div>
</div>
</div>
</section>
<section id="permutations-test-using-scipy">
<h3>Permutations test using SciPy<a class="headerlink" href="#permutations-test-using-scipy" title="Permalink to this headline">#</a></h3>
<p>The above code was given only for illustrative purposes.
In practice, you can use the SciPy implementation of permutation test,
by calling <code class="docutils literal notranslate"><span class="pre">ttest_ind(...,</span> <span class="pre">permutations=10000)</span></code> to perform a permutation test, then obtain the <span class="math notranslate nohighlight">\(p\)</span>-value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">ttest_ind</span>

<span class="n">xS</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;S&quot;</span><span class="p">][</span><span class="s2">&quot;ELV&quot;</span><span class="p">]</span>
<span class="n">xNS</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;NS&quot;</span><span class="p">][</span><span class="s2">&quot;ELV&quot;</span><span class="p">]</span>

<span class="n">ttest_ind</span><span class="p">(</span><span class="n">xS</span><span class="p">,</span> <span class="n">xNS</span><span class="p">,</span> <span class="n">permutations</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0447
</pre></div>
</div>
</div>
</div>
</section>
<section id="discussion">
<h3>Discussion<a class="headerlink" href="#discussion" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>The procedure we used is called a <strong>permutations test</strong> for comparison of group means.</p></li>
<li><p>The permutation test takes it’s name from the action of mixing up the group-membership labels
and computing a statistic which is a way to generate samples from the null hypothesis
in situations where we’re comparing two groups.</p></li>
<li><p>Permutation tests are very versatile since we can use them for any estimator <span class="math notranslate nohighlight">\(h(\mathbf{x})\)</span>.
For example, we could have used difference in medians by specifying the <code class="docutils literal notranslate"><span class="pre">median</span></code> as the input <code class="docutils literal notranslate"><span class="pre">statfunc</span></code>.</p></li>
</ul>
</section>
</section>
<section id="approach-2-analytical-approximations-for-hypothesis-testing">
<h2>Approach 2: Analytical approximations for hypothesis testing<a class="headerlink" href="#approach-2-analytical-approximations-for-hypothesis-testing" title="Permalink to this headline">#</a></h2>
<p>We’ll now look at another approach for answering Question 1:
using and analytical approximation,
which is the way normally taught in STATS 101 courses.
How likely or unlikely is the observed difference <span class="math notranslate nohighlight">\(d=130\)</span> under the null hypothesis?</p>
<ul class="simple">
<li><p>Analytical approximations are math models for describing the sampling distribution under <span class="math notranslate nohighlight">\(H_0\)</span></p>
<ul>
<li><p>Sampling distributions = obtained by repeated sampling from <span class="math notranslate nohighlight">\(H_0\)</span></p></li>
<li><p>Analytical approximation = probability distribution model based on estimated parameters</p></li>
</ul>
</li>
<li><p>Assumption: population is normally distributed</p></li>
<li><p>Based on this assumption we can use the theoretical model we developed above for difference between group means
to obtain a <strong>closed form expression</strong> for the sampling distribution of <span class="math notranslate nohighlight">\(D\)</span></p></li>
<li><p>In particular, the probability model for the two groups under <span class="math notranslate nohighlight">\(H_0\)</span> are:
$<span class="math notranslate nohighlight">\( \large
     H_0: \qquad X_S = \mathcal{N}(\color{red}{\mu_0}, \sigma_S)
     \quad \textrm{and} \quad
     X_{NS} = \mathcal{N}(\color{red}{\mu_0}, \sigma_{NS}), \quad
\)</span><span class="math notranslate nohighlight">\(
from which we can derive the model for \)</span>D = \overline{X}<em>S - \overline{X}</em>{NS}<span class="math notranslate nohighlight">\(:
\)</span><span class="math notranslate nohighlight">\( \large
   D  \sim \mathcal{N}\!\left( \color{red}{0}, \  \tfrac{\sigma^2_S}{n_S} + \tfrac{\sigma^2_{NS}}{n_{NS}} \right)
\)</span><span class="math notranslate nohighlight">\(
In words, the sampling distribution of the difference between group means is
normally distributed with mean \)</span>\mu_D = 0<span class="math notranslate nohighlight">\( and variance \)</span>\sigma^2_D<span class="math notranslate nohighlight">\( dependent
on the variance of the two groups \)</span>\sigma^2_S<span class="math notranslate nohighlight">\( and \)</span>\sigma^2_{NS}$.
Recall we obtained this expression earlier when we discussed difference of means between groups A and B.</p></li>
<li><p>However, the population variances are unknown <span class="math notranslate nohighlight">\(\sigma^2_S\)</span> and <span class="math notranslate nohighlight">\(\sigma^2_{NS}\)</span>,
and we only have the estimated variances <span class="math notranslate nohighlight">\(s_S^2\)</span> and <span class="math notranslate nohighlight">\(s_{NS}^2\)</span> calculated from the sample.</p></li>
<li><p>That’s OK though, since sample variances are good approximation to the population variances.
There are two common ways to obtain an approximation for <span class="math notranslate nohighlight">\(\sigma^2_D\)</span>:</p>
<ul>
<li><p>Pooled variance: <span class="math notranslate nohighlight">\(\sigma^2_D \approx s^2_p =  \frac{(n_S-1)s_S^2 \; + \; (n_{NS}-1)s_{NS}^2}{n_S + n_{NS} - 2}\)</span>
(takes advantage of assumption that both samples come from the same population under <span class="math notranslate nohighlight">\(H_0\)</span>)</p></li>
<li><p>Unpooled variance: <span class="math notranslate nohighlight">\(\sigma^2_D \approx s^2_u = \tfrac{s^2_S}{n_S} + \tfrac{s^2_{NS}}{n_{NS}}\)</span>
(follows from general rule of prob theory)</p></li>
</ul>
</li>
<li><p>NEW CONCEPT: <strong>Student’s <span class="math notranslate nohighlight">\(t\)</span>-distribution</strong> is a model for <span class="math notranslate nohighlight">\(D\)</span> which takes into account
we are using <span class="math notranslate nohighlight">\(s_S^2\)</span> and <span class="math notranslate nohighlight">\(s_{NS}^2\)</span> instead of <span class="math notranslate nohighlight">\(\sigma_S^2\)</span> and <span class="math notranslate nohighlight">\(\sigma_{NS}^2\)</span>.</p></li>
<li><p>NEW CONCEPT: <strong>degrees of freedom</strong>, denoted <code class="docutils literal notranslate"><span class="pre">dof</span></code> in code or <span class="math notranslate nohighlight">\(\nu\)</span> (Greek letter <em>nu</em>) in equations,
is the parameter Student’s <span class="math notranslate nohighlight">\(t\)</span> distribution related to the sample size used to estimate quantities.</p></li>
</ul>
<section id="student-s-t-test-pooled-variance">
<h3>Student’s t-test (pooled variance)<a class="headerlink" href="#student-s-t-test-pooled-variance" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://statkat.com/stattest.php?&amp;t=9">Student’s t-test for comparison of difference between groups means</a>,
is a procedure that makes use of the pooled variance <span class="math notranslate nohighlight">\(s^2_p\)</span>.</p>
<section id="black-box-approach">
<h4>Black-box approach<a class="headerlink" href="#black-box-approach" title="Permalink to this headline">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> function <code class="docutils literal notranslate"><span class="pre">ttest_ind</span></code> will perform all the steps of the <span class="math notranslate nohighlight">\(t\)</span>-test procedure,
without the need for us to understand the details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">ttest_ind</span>

<span class="c1"># extract data for two groups</span>
<span class="n">xS</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;S&quot;</span><span class="p">][</span><span class="s1">&#39;ELV&#39;</span><span class="p">]</span>
<span class="n">xNS</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;NS&quot;</span><span class="p">][</span><span class="s1">&#39;ELV&#39;</span><span class="p">]</span>

<span class="c1"># run the complete t-test procedure for ind-ependent samples:</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">ttest_ind</span><span class="p">(</span><span class="n">xS</span><span class="p">,</span> <span class="n">xNS</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.046999086677830995
</pre></div>
</div>
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(p\)</span>-value is less than 0.05 so our decision is to <strong>reject the null hypothesis</strong>.</p>
</section>
<section id="student-s-t-test-under-the-hood">
<h4>Student’s t-test under the hood<a class="headerlink" href="#student-s-t-test-under-the-hood" title="Permalink to this headline">#</a></h4>
<p>The computations hidden behind the function <code class="docutils literal notranslate"><span class="pre">ttest_ind</span></code> involve a six step procedure that makes use of the pooled variance <span class="math notranslate nohighlight">\(s^2_p\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statistics</span> <span class="kn">import</span> <span class="n">stdev</span>
<span class="kn">from</span> <span class="nn">scipy.stats.distributions</span> <span class="kn">import</span> <span class="n">t</span>

<span class="c1"># 1. calculate the mean in each group</span>
<span class="n">meanS</span><span class="p">,</span> <span class="n">meanNS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>

<span class="c1"># 2. calculate d, the observed difference between means</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">meanS</span> <span class="o">-</span> <span class="n">meanNS</span>

<span class="c1"># 3. calculate the standard deviations in each group</span>
<span class="n">stdS</span><span class="p">,</span> <span class="n">stdNS</span> <span class="o">=</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
<span class="n">nS</span><span class="p">,</span> <span class="n">nNS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>

<span class="c1"># 4. compute the pooled variance and standard error</span>
<span class="n">var_pooled</span> <span class="o">=</span> <span class="p">((</span><span class="n">nS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">nNS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nS</span> <span class="o">+</span> <span class="n">nNS</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">std_pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_pooled</span><span class="p">)</span>
<span class="n">std_err</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">std_pooled</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="n">std_pooled</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span>

<span class="c1"># 5. compute the value of the t-statistic</span>
<span class="n">tstat</span> <span class="o">=</span> <span class="n">d</span> <span class="o">/</span> <span class="n">std_err</span>

<span class="c1"># 6. obtain the p-value for the t-statistic from a </span>
<span class="c1">#    t-distribution with 31+30-2 = 59 degrees of freedom</span>
<span class="n">dof</span> <span class="o">=</span> <span class="n">nS</span> <span class="o">+</span> <span class="n">nNS</span> <span class="o">-</span> <span class="mi">2</span>
<span class="n">pvalue</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">t</span><span class="p">(</span><span class="n">dof</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">tstat</span><span class="p">))</span>  <span class="c1"># 2* because two-sided</span>

<span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.046999086677830995
</pre></div>
</div>
</div>
</div>
</section>
<section id="welch-s-t-test-unpooled-variances">
<h4>Welch’s t-test (unpooled variances)<a class="headerlink" href="#welch-s-t-test-unpooled-variances" title="Permalink to this headline">#</a></h4>
<p>An <a class="reference external" href="https://statkat.com/stattest.php?&amp;t=9">alternative t-test procedure</a> that doesn’t assume the variances in groups are equal.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result2</span> <span class="o">=</span> <span class="n">ttest_ind</span><span class="p">(</span><span class="n">xS</span><span class="p">,</span> <span class="n">xNS</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">result2</span><span class="o">.</span><span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.046579019827041344
</pre></div>
</div>
</div>
</div>
<p>Welch’s <span class="math notranslate nohighlight">\(t\)</span>-test differs only in steps 4 through 6 as shown below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4&#39;. compute the unpooled standard deviation of D</span>
<span class="n">stdD</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span>

<span class="c1"># 5&#39;. compute the value of the t-statistic</span>
<span class="n">tstat</span> <span class="o">=</span> <span class="n">d</span> <span class="o">/</span> <span class="n">stdD</span>

<span class="c1"># 6&#39;. obtain the p-value from a t-distribution with</span>
<span class="c1">#     (insert crazy formula here) degrees of freedom</span>
<span class="n">dof</span> <span class="o">=</span> <span class="p">(</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> \
    <span class="p">((</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">nS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">nNS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
<span class="n">pvalue</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">t</span><span class="p">(</span><span class="n">dof</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">tstat</span><span class="p">))</span>  <span class="c1"># 2* because two-sided</span>

<span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.04657901982704139
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="summary-of-question-1">
<h3>Summary of Question 1<a class="headerlink" href="#summary-of-question-1" title="Permalink to this headline">#</a></h3>
<p>We saw two ways to answer Question 1 (is there a difference between group means) and obtain the p-value.
We interpreted the small p-values as evidence that the observed difference, <span class="math notranslate nohighlight">\(d=130\)</span>, is unlikely to be due to chance,
i.e. we rejected the null hypothesis.
Note this whole procedure is just a sanity check—we haven’t touched the alternative hypothesis at all yet,
and for all we know the stats training could have the effect of decreasing ELV!</p>
<hr class="docutils" />
<p>It’s time to study Question 2, which is to estimate the magnitude of the change in ELV obtained from completing the stats training, which is called <em>effect size</em> in statistics.</p>
</section>
</section>
<section id="estimating-the-effect-size">
<h2>Estimating the effect size<a class="headerlink" href="#estimating-the-effect-size" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Question 2 of statistical analysis is to estimate the difference in ELV gained by stats training.</p></li>
<li><p>NEW CONCEPT: <strong>effect size</strong> is a measure of difference between intervention and control groups.</p></li>
<li><p>We assume the data of <strong>Group S</strong> and <strong>Group NS</strong> come from different populations with means <span class="math notranslate nohighlight">\(\mu_S\)</span> and <span class="math notranslate nohighlight">\(\mu_{NS}\)</span></p></li>
<li><p>We’re interested in the difference between population means, denoted <span class="math notranslate nohighlight">\(\Delta = \mu_S - \mu_{NS}\)</span>.</p></li>
<li><p>By analyzing the sample, we have obtained an estimate <span class="math notranslate nohighlight">\(d=130\)</span> for the unknown <span class="math notranslate nohighlight">\(\Delta\)</span>,
but we know our data contains lots of variability, so we know our estimate might be off.</p></li>
<li><p>We want an answer to Question 2 (What is the estimated difference between group means?)
that takes into account the variability of the data.</p></li>
<li><p>NEW CONCEPT: <strong>confidence interval</strong> is a way to describe a range of values for an estimate</p></li>
<li><p>We want to provide an answer to Question 2 in the form of a confidence interval that tells
us a range of values where we believe the true value of <span class="math notranslate nohighlight">\(\Delta\)</span> falls.</p></li>
<li><p>Similar to how we showed to approaches for hypothesis testing,
we’ll work on effect size estimation using two approaches: resampling methods and analytical approximations.</p></li>
</ul>
<section id="approach-1-estimate-the-effect-size-using-bootstrap-method">
<h3>Approach 1: estimate the effect size using bootstrap method<a class="headerlink" href="#approach-1-estimate-the-effect-size-using-bootstrap-method" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>We want to estimate the distribution of ELV values for the two groups,
and compute the difference between the means of these distributions.</p></li>
<li><p>Distributions:</p>
<ul>
<li><p>Sampling distributions = obtained by repeated sampling from the populations</p></li>
<li><p>Bootstrap sampling distributions = resampling data from the samples we have (with replacement)</p></li>
</ul>
</li>
<li><p>Intuition: treat the samples as if they were the population</p></li>
<li><p>We’ll compute <span class="math notranslate nohighlight">\(B=5000\)</span> bootstrap samples from the two groups and compute the difference,
then look at the distribution of the bootstrap sample difference to obtain <span class="math notranslate nohighlight">\(CI_{\Delta}\)</span>,
the confidence interval for the difference between population means.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statistics</span> <span class="kn">import</span> <span class="n">mean</span>

<span class="k">def</span> <span class="nf">bootstrap_stat</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">statfunc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the bootstrap estimate of the function `statfunc` from the sample.</span>
<span class="sd">    Returns a list of statistic values from bootstrap samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">bstats</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
        <span class="n">bsample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">bstat</span> <span class="o">=</span> <span class="n">statfunc</span><span class="p">(</span><span class="n">bsample</span><span class="p">)</span>
        <span class="n">bstats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bstat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bstats</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load data for two groups</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/employee_lifetime_values.csv&#39;</span><span class="p">)</span>
<span class="n">xS</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;S&quot;</span><span class="p">][</span><span class="s1">&#39;ELV&#39;</span><span class="p">]</span>
<span class="n">xNS</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;NS&quot;</span><span class="p">][</span><span class="s1">&#39;ELV&#39;</span><span class="p">]</span>

<span class="c1"># compute bootstrap estimates for mean in each group</span>
<span class="n">meanS_bstats</span> <span class="o">=</span> <span class="n">bootstrap_stat</span><span class="p">(</span><span class="n">xS</span><span class="p">,</span> <span class="n">statfunc</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>
<span class="n">meanNS_bstats</span> <span class="o">=</span> <span class="n">bootstrap_stat</span><span class="p">(</span><span class="n">xNS</span><span class="p">,</span> <span class="n">statfunc</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>

<span class="c1"># compute the difference between means from bootstrap samples</span>
<span class="n">dmeans_bstats</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">bmeanS</span><span class="p">,</span> <span class="n">bmeanNS</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">meanS_bstats</span><span class="p">,</span> <span class="n">meanNS_bstats</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">bmeanS</span> <span class="o">-</span> <span class="n">bmeanNS</span> 
    <span class="n">dmeans_bstats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">dmeans_bstats</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.FacetGrid at 0x7faa9a8d92e0&gt;
</pre></div>
</div>
<img alt="../_images/03_STATS_80_1.png" src="../_images/03_STATS_80_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 90% confidence interval for the difference in means</span>
<span class="n">CI_boot</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">dmeans_bstats</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">dmeans_bstats</span><span class="p">,</span> <span class="mi">95</span><span class="p">)]</span>
<span class="n">CI_boot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[28.3957801075268, 237.55493602150537]
</pre></div>
</div>
</div>
</div>
<section id="scipy-bootstrap-method">
<h4>SciPy bootstrap method<a class="headerlink" href="#scipy-bootstrap-method" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">bootstrap</span>

<span class="k">def</span> <span class="nf">dmeans2</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample2</span><span class="p">)</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">bootstrap</span><span class="p">((</span><span class="n">xS</span><span class="p">,</span> <span class="n">xNS</span><span class="p">),</span> <span class="n">statistic</span><span class="o">=</span><span class="n">dmeans2</span><span class="p">,</span> <span class="n">vectorized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">n_resamples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;percentile&#39;</span><span class="p">)</span>

<span class="n">CI_boot2</span> <span class="o">=</span> <span class="p">[</span><span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span><span class="o">.</span><span class="n">low</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span><span class="o">.</span><span class="n">high</span><span class="p">]</span>
<span class="n">CI_boot2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[26.55480537634374, 234.32339731182762]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="approach-2-estimates-using-analytical-approximation-method">
<h3>Approach 2: Estimates using analytical approximation method<a class="headerlink" href="#approach-2-estimates-using-analytical-approximation-method" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Assumption 1: populations for <strong>Group S</strong> and <strong>Group NS</strong> are normally distributed</p></li>
<li><p>Assumption 2: the variance of the two populations is the same (or approximately equal)</p></li>
<li><p>Using the theoretical model for the populations,
we can obtain a formula for CI of effect size <span class="math notranslate nohighlight">\(\Delta\)</span>:
$<span class="math notranslate nohighlight">\(
\textrm{CI}_{(1-\alpha)}
= \left[ d - t^*\!\cdot\!\sigma_D, \, 
         d + t^*\!\cdot\!\sigma_D
  \right].
\)</span><span class="math notranslate nohighlight">\(
The confidence interval is centred at \)</span>d<span class="math notranslate nohighlight">\(,
with width proportional to the standard deviation \)</span>\sigma_D<span class="math notranslate nohighlight">\(.
The constant \)</span>t^<em><span class="math notranslate nohighlight">\( denotes the value of the inverse CDF of Student's \)</span>t<span class="math notranslate nohighlight">\(-distribution
with appropriate number of degrees of freedom `dof` evaluated at \)</span>1-\frac{\alpha}{2}<span class="math notranslate nohighlight">\(.
For a 90% confidence interval, we choose \)</span>\alpha=0.10<span class="math notranslate nohighlight">\(,
which gives \)</span>(1-\frac{\alpha}{2}) = 0.95<span class="math notranslate nohighlight">\(, \)</span>t^</em> = F_{T_{\textrm{dof}}}^{-1}\left(0.95\right)$.</p></li>
<li><p>We can use the two different analytical approximations to obtain a formula for <span class="math notranslate nohighlight">\(\sigma_D\)</span>
just as we did in the hypothesis testing:</p>
<ul>
<li><p>Pooled variance: <span class="math notranslate nohighlight">\(\sigma^2_p =  \frac{(n_S-1)s_S^2 + (n_{NS}-1)s_{NS}^2}{n_S + n_{NS} - 2}\)</span>,
and <code class="docutils literal notranslate"><span class="pre">dof</span></code> = <span class="math notranslate nohighlight">\(n_S + n_{NS} -2\)</span></p></li>
<li><p>Unpooled variance: <span class="math notranslate nohighlight">\(\sigma^2_u = \tfrac{s^2_A}{n_A} + \tfrac{s^2_B}{n_B}\)</span>, and <code class="docutils literal notranslate"><span class="pre">dof</span></code> = <a class="reference external" href="https://en.wikipedia.org/wiki/Student%27s_t-test#Equal_or_unequal_sample_sizes,_unequal_variances_(sX1_%3E_2sX2_or_sX2_%3E_2sX1)">…</a></p></li>
</ul>
</li>
</ul>
<section id="using-pooled-variance">
<h4>Using pooled variance<a class="headerlink" href="#using-pooled-variance" title="Permalink to this headline">#</a></h4>
<p>The calculations are similar to Student’s t-test for hypothesis testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats.distributions</span> <span class="kn">import</span> <span class="n">t</span>

<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xS</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>

<span class="n">nS</span><span class="p">,</span> <span class="n">nNS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
<span class="n">stdS</span><span class="p">,</span> <span class="n">stdNS</span> <span class="o">=</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
<span class="n">var_pooled</span> <span class="o">=</span> <span class="p">((</span><span class="n">nS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">nNS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nS</span> <span class="o">+</span> <span class="n">nNS</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">std_pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_pooled</span><span class="p">)</span>
<span class="n">std_err</span> <span class="o">=</span> <span class="n">std_pooled</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span>

<span class="n">dof</span> <span class="o">=</span> <span class="n">nS</span> <span class="o">+</span> <span class="n">nNS</span> <span class="o">-</span> <span class="mi">2</span>

<span class="c1"># for 90% confidence interval, need 10% in tails</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.10</span>

<span class="c1"># now use inverse-CDF of Students t-distribution</span>
<span class="n">tstar</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">dof</span><span class="p">)</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

<span class="n">CI_tpooled</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="o">-</span> <span class="n">tstar</span><span class="o">*</span><span class="n">std_err</span><span class="p">,</span> <span class="n">d</span> <span class="o">+</span> <span class="n">tstar</span><span class="o">*</span><span class="n">std_err</span><span class="p">]</span>
<span class="n">CI_tpooled</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[22.925130302086643, 237.12228905275202]
</pre></div>
</div>
</div>
</div>
</section>
<section id="using-unpooled-variance">
<h4>Using unpooled variance<a class="headerlink" href="#using-unpooled-variance" title="Permalink to this headline">#</a></h4>
<p>The calculations are similar to the Welch’s t-test for hypothesis testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xS</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>

<span class="n">nS</span><span class="p">,</span> <span class="n">nNS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
<span class="n">stdS</span><span class="p">,</span> <span class="n">stdNS</span> <span class="o">=</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
<span class="n">stdD</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span>

<span class="n">dof</span> <span class="o">=</span> <span class="p">(</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> \
    <span class="p">((</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">nS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">nNS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>

<span class="c1"># for 90% confidence interval, need 10% in tails</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.10</span>

<span class="c1"># now use inverse-CDF of Students t-distribution</span>
<span class="n">tstar</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">dof</span><span class="p">)</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

<span class="n">CI_tunpooled</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="o">-</span> <span class="n">tstar</span><span class="o">*</span><span class="n">stdD</span><span class="p">,</span> <span class="n">d</span> <span class="o">+</span> <span class="n">tstar</span><span class="o">*</span><span class="n">stdD</span><span class="p">]</span>
<span class="n">CI_tunpooled</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[23.14219839967336, 236.9052209551653]
</pre></div>
</div>
</div>
</div>
</section>
<section id="summary-of-question-2-results">
<h4>Summary of Question 2 results<a class="headerlink" href="#summary-of-question-2-results" title="Permalink to this headline">#</a></h4>
<p>We now have all the information we need to give a precise and nuanced answer to Question 2: “How big is the increase in ELV produced by stats training?”.</p>
<p>The basic estimate of the difference is <span class="math notranslate nohighlight">\(130\)</span> can be reported, and additionally can can report the 90% confidence interval for the difference between group means, that takes into account the variability in the data we have observed.</p>
<p>Note the CIs obtained using different approaches are all similar (+/- 5 ELV points), so it doesn’t matter much which approach we use:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CI_boot</span><span class="p">,</span> <span class="n">CI_boot2</span><span class="p">,</span> <span class="n">CI_tpooled</span><span class="p">,</span> <span class="n">CI_tunpooled</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>([28.3957801075268, 237.55493602150537],
 [26.55480537634374, 234.32339731182762],
 [22.925130302086643, 237.12228905275202],
 [23.14219839967336, 236.9052209551653])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="standardized-effect-size-optional">
<h3>Standardized effect size (optional)<a class="headerlink" href="#standardized-effect-size-optional" title="Permalink to this headline">#</a></h3>
<p>It is sometimes useful to report the effect size using a “standardized” measure for effect sizes.
<em>Cohen’s <span class="math notranslate nohighlight">\(d\)</span></em> one such measure, and it is defined as the difference between two means divided by the pooled  standard deviation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cohend</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Cohen&#39;s d measure of effect size for two independent samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample2</span><span class="p">)</span>
    <span class="n">mean1</span><span class="p">,</span> <span class="n">mean2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample2</span><span class="p">)</span>
    <span class="n">var1</span><span class="p">,</span> <span class="n">var2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">sample2</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># calculate the pooled variance and standard deviaiton</span>
    <span class="n">var_pooled</span> <span class="o">=</span> <span class="p">((</span><span class="n">n1</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">var1</span> <span class="o">+</span> <span class="p">(</span><span class="n">n2</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">var2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">std_pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_pooled</span><span class="p">)</span>
    <span class="c1"># compute Cohen&#39;s d</span>
    <span class="n">cohend</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean1</span> <span class="o">-</span> <span class="n">mean2</span><span class="p">)</span> <span class="o">/</span> <span class="n">std_pooled</span>
    <span class="k">return</span> <span class="n">cohend</span>

<span class="n">cohend</span><span class="p">(</span><span class="n">xS</span><span class="p">,</span> <span class="n">xNS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5195925482978414
</pre></div>
</div>
</div>
</div>
<p>We can interpret the value of Cohen’s d obtained using the <a class="reference external" href="https://en.wikipedia.org/wiki/Effect_size#Cohen%27s_d">reference table</a> of values:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Cohen’s d</p></th>
<th class="head"><p>Effect size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0.01</p></td>
<td><p>very small</p></td>
</tr>
<tr class="row-odd"><td><p>0.20</p></td>
<td><p>small</p></td>
</tr>
<tr class="row-even"><td><p>0.50</p></td>
<td><p>medium</p></td>
</tr>
<tr class="row-odd"><td><p>0.80</p></td>
<td><p>large</p></td>
</tr>
</tbody>
</table>
<p>We can therefore say the effect size of offering statistics training for employees has an <strong>medium</strong> effect size.</p>
</section>
</section>
<section id="conclusion-of-amy-s-statistical-analysis">
<h2>Conclusion of Amy’s statistical analysis<a class="headerlink" href="#conclusion-of-amy-s-statistical-analysis" title="Permalink to this headline">#</a></h2>
<p>Recall the two research questions that Amy set out to answer in the beginning of this video series:</p>
<ul class="simple">
<li><p>Question 1: Is there a difference between the means in the two groups?</p></li>
<li><p>Question 2: How much does statistics training improve the ELV of employees?</p></li>
</ul>
<p>The statistical analysis we did allows us to answer these two questions as follows:</p>
<ul class="simple">
<li><p>Answer 1: There is a statistically significant difference between Group S and Group NS, p = 0.048.</p></li>
<li><p>Answer 2: The estimated improvement in ELV is 130 points, which is corresponds to Cohen’s d value of 0.52 (medium effect size). A 90% confidence interval for the true effect size is [25.9, 234.2].</p></li>
</ul>
<p>Note: we used the numerical results obtained from resampling methods (Approach 1), but conclusions would be qualitatively the same if we reported results obtained from analytical approximations (Approach 2).</p>
<section id="using-statistics-for-convincing-others">
<h3>Using statistics for convincing others<a class="headerlink" href="#using-statistics-for-convincing-others" title="Permalink to this headline">#</a></h3>
<p>You may be wondering if all this probabilistic modelling and complicated statistical analysis was worth it to reach a conclusion that seems obvious in retrospect. Was all this work worth it? The purpose of all this work is to obtains something close to an objective conclusion. Without statistics it is very easy to fool ourselves and interpret patterns in data the way we want to, or alternatively, not see patterns that are present. By following the standard statistical procedures, we’re less likely to fool ourselves, and more likely to be able to convince others.</p>
<p>It can very useful to imagine Amy explaining the results to a skeptical colleague. Suppose the colleague is very much against the idea of statistical training, and sees it as a distraction, saying things like “We hire employees to do a job, not to play with Python.” and “I don’t know any statistics and I’m doing my job just fine!” You get the picture.</p>
<p>Imagine Amy presenting her findings about how 100 hours of statistical training improves employee lifetime value (ELV) results after one year, and suggesting the statistical training be implemented for all new hires from now on. The skeptical colleague immediately rejects the idea and questions Amy’s recommendation using emotional arguments like about necessity, time wasting, and how statistics is a specialty topic that is not required for all employees. Instead of arguing based on opinions and emotions with her colleague, Amy explains her recommendation is based on a statistical experiment she conducted, and shows the results.</p>
<ul class="simple">
<li><p>When the colleague asks if the observed difference could be due to chance, Amy says that this is unlikely, and quotes the p-value of 0.048 (less than 0.05), and interprets the result as saying the probability of observed difference between <strong>Group S</strong> and <strong>Group NS</strong> to be due to chance is less than 5%.</p></li>
<li><p>The skeptical colleague is forced to concede that statistical training does improve ELV, but then asks about the effect size of the improvement: “How much more ELV can we expect if we provide statistics training?” Amy is ready to answer quoting the observed difference of <span class="math notranslate nohighlight">\(130\)</span> ELV points, and further specifies the 90% confidence interval of [25.9, 234.2] for the improvement, meaning in the worst case there is 25 ELV points improvement.</p></li>
</ul>
<p>The skeptic is forced to back down from their objections, and the “stats training for all” program is adopted in the company. Not only was Amy able to win the argument using statistics, but she was also able to set appropriate expectations for the results. In other words, she hasn’t promised a guaranteed +130 ELV improvement, but a realistic range of values that can be expected.</p>
</section>
</section>
<section id="comparison-of-resampling-methods-and-analytical-approximations">
<h2>Comparison of resampling methods and analytical approximations<a class="headerlink" href="#comparison-of-resampling-methods-and-analytical-approximations" title="Permalink to this headline">#</a></h2>
<p>In this notebook we saw two different approaches for doing statistical analysis: resampling methods and analytical approximations. This is a general pattern in statistics where there is not only one correct answer: multiple approaches to data analysis are valid, and you need to think about the specifics of each data analysis situation. You’ll learn about both approaches in the book.</p>
<p>Analytical approximations currently taught in most stats courses (STAT 101). Historically, analytical approximations have been used more widely because they require only simple arithmetic calculations: statistic practitioners (scientists, engineers, etc.) simply need to compute sample statistics, plug them into a formula, and obtain a <span class="math notranslate nohighlight">\(p\)</span>-value. This convenience is at the cost of numerous assumptions about the data distribution, which often don’t hold in practice (e.g. assuming population is normal, when it is isn’t).</p>
<p>In recent years, resampling methods like the permutation test and bootstrap estimation are becoming more popular and widely in industry, and increasingly also taught at to university students (<em>modern statistics</em>). <strong>The main advantage so resampling methods is that they require less modelling assumptions.</strong> Procedures like the permutation test can be applied broadly to any scenarios where two groups are compared, and don’t require developing specific formulas for different cases. Resampling methods are easier to understand since the statistical procedure they require are directly related to the sampling distribution, and there are no formulas to memorize.</p>
<p>Understanding resampling methods requires some basic familiarity with programming, but the skills required are not advanced: knowledge of variables, expressions, and basic <code class="docutils literal notranslate"><span class="pre">for</span></code> loop is sufficient. If you were able to follow the code examples described above (see <code class="docutils literal notranslate"><span class="pre">resample_under_H0</span></code>, <code class="docutils literal notranslate"><span class="pre">permutation_test</span></code>, and <code class="docutils literal notranslate"><span class="pre">bootstrap_stat</span></code>), then you’ve already <strong>seen all the code you will need for the entire book!</strong></p>
</section>
<section id="other-statistics-topics-in-the-book">
<h2>Other statistics topics in the book<a class="headerlink" href="#other-statistics-topics-in-the-book" title="Permalink to this headline">#</a></h2>
<p>The goal of this notebook was to focus on the two main ideas of inferential statistics (<a class="reference external" href="https://docs.google.com/document/d/1fwep23-95U-w1QMPU31nOvUnUXE2X3s_Dbk5JuLlKAY/edit#heading=h.uutryzqeo2av">Chapter 3</a>): hypothesis testing and estimation. We didn’t have time to cover many of the other important topics in statistics, which will be covered in the book (and in future notebooks). Here is a list of some of these topics:</p>
<ul class="simple">
<li><p>Null Hypothesis Significance Testing (NHST) procedure in full details (Type I and Type II error, power, sample size calculations)</p></li>
<li><p>Statistical assumptions behind analytical approximations</p></li>
<li><p>Cookbook of statistical analysis recipes (analytical approximations for different scenarios)</p></li>
<li><p>Experimental design (how to plan and conduct statistical experiments)</p></li>
<li><p>Misuses of statistics (caveats to watch out for and mistakes to avoid)</p></li>
<li><p>Bayesian statistics (very deep topic; we’ll cover only main ideas)</p></li>
<li><p>Practice problems and exercises (real knowledge is when you can do the calculations yourself)</p></li>
</ul>
<hr class="docutils" />
<p>So far our statistical analysis was limited to comparing two groups, which is referred to as <strong>categorical predictor variable</strong> using stats jargon. In the next notebook we’ll learn about statistical analysis with <strong>continuous predictor variables</strong>: instead of comparing stats vs. no-stats, we analyze what happens when variable amount of stats training is provided (a continuous predictor variable).</p>
<p>Open the notebook <a class="reference internal" href="04_LINEAR_MODELS.html"><span class="doc std std-doc">04_LINEAR_MODELS.ipynb</span></a> when you’re ready to continue.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">code</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span><span class="s2">&quot;um&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "minireference/noBSstatsnotebooks",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./stats_overview"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="02_PROB.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Chapter 2: Probability theory</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="04_LINEAR_MODELS.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 4: Linear models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ivan Savov<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>